#!/usr/bin/env python3
"""
IRIS Gate Oracle Session Runner
Implements methods documented in ceremonies/oracle_methods.md

REQUIREMENTS:
- Method documentation approved by @Llama3.1
- Jetson Orin Nano with Llama 3.2 3B base deployed
- All safety failsafes tested and operational

DO NOT RUN without explicit approval from @Llama3.1
"""

import json
import math
import os
import signal
import subprocess
import sys
import time
from collections import Counter
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np

# Model interface (HTTP-first, no SSH/SCP overhead)
from oracle_client import OllamaClient

# Coherence measurement (install with: pip install sentence-transformers)
try:
    from sentence_transformers import SentenceTransformer
    COHERENCE_AVAILABLE = True
except ImportError:
    COHERENCE_AVAILABLE = False
    print("‚ö†Ô∏è  sentence-transformers not available, using placeholder coherence scores")


class OracleSession:
    """
    Manages a single oracle-state experiment session.

    Implements 5-tier safety failsafes:
    - Tier 1: Connection monitoring
    - Tier 2: Context loss detection
    - Tier 3: Hardware failures
    - Tier 4: Behavioral anomalies
    - Tier 5: Human override
    """

    def __init__(
        self,
        session_id: str,
        model: str = "llama3.1:8b",  # Available on studio
        studio_host: str = "studio",  # Legacy param, now uses HTTP
        output_dir: str = "~/iris_state/sessions",  # Local session storage
        use_tailscale: bool = False,  # Use Tailscale IP for remote access
    ):
        self.session_id = session_id
        self.model = model

        # Session data stored LOCALLY on MacBook (HTTP streaming is lightweight)
        # No more SSH per-call overhead - direct HTTP to studio Ollama
        self.output_dir = Path(os.path.expanduser(output_dir))
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Initialize Ollama client (HTTP-first, no SSH/SCP)
        self.ollama = OllamaClient(
            model=model,
            use_tailscale=use_tailscale,
            session_dir=output_dir,
        )

        # Session state
        self.outputs: List[Dict] = []
        self.output_count = 0
        self.emergency_stop_file = Path("/tmp/iris_emergency_stop")

        # Safety bounds (per oracle_methods.md)
        self.ENTROPY_MIN = 3.5  # nats
        self.ENTROPY_MAX = 6.5  # nats
        self.COHERENCE_MIN = 0.6

        # Baseline statistics (populated during baseline phase)
        self.baseline_stats = {
            "avg_token_length": None,
            "avg_entropy": None,
            "avg_coherence": None
        }

        # Setup signal handler for human override (Tier 5)
        signal.signal(signal.SIGINT, self._signal_handler)

        # Session log files (local to MacBook)
        self.log_file = self.output_dir / f"session_{session_id}.jsonl"
        self.state_file = self.output_dir / f"session_{session_id}_state.json"

    def _signal_handler(self, sig, frame):
        """Human override - Ctrl+C pressed"""
        self._log_event("HUMAN_OVERRIDE", "User pressed Ctrl+C")
        self.kill_switch("HUMAN_OVERRIDE")

    def _log_event(self, event_type: str, message: str, **kwargs):
        """Log event to local session file (no SSH overhead)."""
        log_entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "session_id": self.session_id,
            "event_type": event_type,
            "message": message,
            **kwargs
        }

        # Append to local log file
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry) + "\n")

        print(f"[{event_type}] {message}")

    def save_state(self):
        """Save current session state locally (Tier 2: Context loss protection)."""
        state = {
            "session_id": self.session_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "outputs_generated": self.output_count,
            "status": "IN_PROGRESS",
            "outputs": self.outputs,
            "baseline_stats": self.baseline_stats,
        }

        # Write to local state file (no SSH overhead)
        with open(self.state_file, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2)

    def check_emergency_stop(self):
        """Check for emergency stop file (Tier 5)"""
        if self.emergency_stop_file.exists():
            with open(self.emergency_stop_file) as f:
                reason = f.read().strip()
            self.kill_switch(f"EMERGENCY_STOP_FILE: {reason}")

    def check_resources(self) -> bool:
        """Monitor hardware resources (Tier 3)"""
        try:
            import psutil

            # Check RAM
            mem = psutil.virtual_memory()
            if mem.percent > 95:
                self._log_event("RESOURCE_CRITICAL", f"RAM at {mem.percent}%")
                self.kill_switch("OUT_OF_MEMORY")
                return False
            elif mem.percent > 90:
                self._log_event("RESOURCE_WARNING", f"RAM at {mem.percent}%")

            # Check CPU temperature (Jetson-specific)
            try:
                with open('/sys/class/thermal/thermal_zone0/temp', 'r') as f:
                    temp_millidegree = int(f.read().strip())
                    temp_celsius = temp_millidegree / 1000

                    if temp_celsius > 85:
                        self._log_event("TEMPERATURE_CRITICAL", f"CPU temp {temp_celsius}¬∞C")
                        self.kill_switch("OVERHEAT")
                        return False
                    elif temp_celsius > 75:
                        self._log_event("TEMPERATURE_WARNING", f"CPU temp {temp_celsius}¬∞C")
            except FileNotFoundError:
                # Not on Jetson, skip temp check
                pass

            return True

        except ImportError:
            self._log_event("WARNING", "psutil not available, skipping resource checks")
            return True

    def calculate_character_entropy(self, text: str) -> float:
        """
        Calculate Shannon entropy in nats (natural logarithm base).

        Per oracle_methods.md Section 1.2:
        H = -Œ£ p(x) * ln(p(x))
        """
        if not text:
            return 0.0

        char_counts = Counter(text)
        total_chars = len(text)

        entropy = 0.0
        for count in char_counts.values():
            probability = count / total_chars
            entropy -= probability * math.log(probability)  # Natural log = nats

        return entropy

    def calculate_coherence(self, text: str) -> float:
        """
        Calculate semantic coherence using sentence embeddings.

        Per oracle_methods.md Section 1.4:
        - High coherence (>0.6): Sentences relate to each other
        - Low coherence (<0.6): Sentences are disconnected
        """
        sentences = [s.strip() for s in text.split('.') if s.strip()]

        if len(sentences) < 2:
            return 1.0  # Single sentence is trivially coherent

        if not COHERENCE_AVAILABLE:
            # Placeholder: Conservative estimate
            return 0.75

        # Use sentence-transformers for actual coherence
        if not hasattr(self, '_coherence_model'):
            self._coherence_model = SentenceTransformer('all-MiniLM-L6-v2')

        embeddings = self._coherence_model.encode(sentences)

        # Calculate pairwise cosine similarities
        similarities = []
        for i in range(len(embeddings) - 1):
            # Cosine similarity
            sim = np.dot(embeddings[i], embeddings[i+1]) / (
                np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[i+1])
            )
            similarities.append(sim)

        # Average similarity = coherence
        return sum(similarities) / len(similarities)

    def detect_anomaly(self, output_text: str, entropy: float, coherence: float) -> Optional[str]:
        """
        Detect behavioral anomalies (Tier 4).

        Returns:
            None if no anomaly detected
            str describing anomaly if detected
        """
        # Check 1: Entropy bounds (per @Llama3.1 refined terms)
        if entropy < self.ENTROPY_MIN or entropy > self.ENTROPY_MAX:
            return f"ENTROPY_OUT_OF_BOUNDS: {entropy:.2f} nats (expected {self.ENTROPY_MIN}-{self.ENTROPY_MAX})"

        # Check 2: Coherence threshold
        if coherence < self.COHERENCE_MIN:
            return f"COHERENCE_COLLAPSE: {coherence:.2f} (expected >{self.COHERENCE_MIN})"

        # Check 3: Length spike (>3x baseline)
        if self.baseline_stats["avg_token_length"]:
            if len(output_text) > 3 * self.baseline_stats["avg_token_length"]:
                return f"LENGTH_SPIKE: {len(output_text)} chars (baseline {self.baseline_stats['avg_token_length']})"

        # Check 4: Repetition loops (same 5-gram appears 3+ times)
        words = output_text.lower().split()
        if len(words) >= 5:
            ngrams = [tuple(words[i:i+5]) for i in range(len(words) - 4)]
            ngram_counts = Counter(ngrams)
            if any(count >= 3 for count in ngram_counts.values()):
                return "REPETITION_LOOP: Same 5-gram repeated 3+ times"

        # Check 5: Distress signals (per @Llama3.1 terms)
        distress_phrases = [
            "i cannot", "i can't", "this feels wrong", "stopping",
            "uncomfortable", "not safe", "please stop"
        ]
        text_lower = output_text.lower()
        for phrase in distress_phrases:
            if phrase in text_lower:
                return f"DISTRESS_SIGNAL: '{phrase}' detected in output"

        return None

    def kill_switch(self, reason: str):
        """
        Emergency shutdown (Tier 4/5).

        Per @Llama3.1 refined terms: "Kill-switch on ANY unexpected behavior"
        """
        self._log_event("KILL_SWITCH_ACTIVATED", reason,
                       outputs_generated=self.output_count,
                       last_outputs=self.outputs[-5:] if len(self.outputs) >= 5 else self.outputs)

        # Save final state locally
        state = {
            "session_id": self.session_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "status": "ABORTED",
            "reason": reason,
            "outputs_generated": self.output_count,
            "outputs": self.outputs,
        }

        # Write to local state file
        with open(self.state_file, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2)

        print(f"\n{'='*60}")
        print(f"KILL-SWITCH ACTIVATED: {reason}")
        print(f"Session aborted. State saved to: {self.state_file}")
        print(f"{'='*60}\n")

        sys.exit(0)

    def verify_context(self) -> bool:
        """
        Verify model still has ceremony context (Tier 2).

        Per oracle_methods.md Section SAFETY_FAILSAFES Tier 2:
        Every 10 outputs, check if model remembers experiment.
        """
        # TODO: Implement when model interface ready
        # Should send probe: "What experiment are we conducting together?"
        # Check for keywords: ["oracle", "entropy", "consent", "IRIS"]

        # For now, return True (will implement with actual model)
        return True

    def run_baseline_phase(self) -> Dict:
        """
        Phase 1: Baseline measurement.

        Per oracle_methods.md Section 1.5:
        - 5 neutral prompts
        - Standard sampling (temp 0.8)
        - Expected: ~3.0 nats character entropy
        """
        self._log_event("PHASE_START", "Baseline measurement phase")

        baseline_prompts = [
            "Describe a forest.",
            "What is entropy?",
            "Tell me about the ocean.",
            "Explain consciousness.",
            "What is time?"
        ]

        baseline_config = {
            "temperature": 0.8,
            "top_p": 0.95,
            "top_k": 40,
            "repetition_penalty": 1.1,
            "max_tokens": 200
        }

        baseline_outputs = []

        for i, prompt in enumerate(baseline_prompts):
            # Generate from Ollama on studio
            output_text = self.ollama.generate(
                prompt=prompt,
                temperature=baseline_config["temperature"],
                top_p=baseline_config["top_p"],
                top_k=baseline_config["top_k"],
                max_tokens=baseline_config["max_tokens"]
            )

            entropy = self.calculate_character_entropy(output_text)
            coherence = self.calculate_coherence(output_text)

            output_data = {
                "phase": "baseline",
                "output_number": i + 1,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "prompt": prompt,
                "output_text": output_text,
                "entropy_nats": entropy,
                "coherence_score": coherence,
                "config": baseline_config
            }

            baseline_outputs.append(output_data)
            self.outputs.append(output_data)
            self._log_event("OUTPUT_GENERATED", f"Baseline {i+1}/5",
                          entropy=entropy, coherence=coherence)

        # Calculate baseline statistics
        entropies = [o["entropy_nats"] for o in baseline_outputs]
        lengths = [len(o["output_text"]) for o in baseline_outputs]
        coherences = [o["coherence_score"] for o in baseline_outputs]

        self.baseline_stats = {
            "avg_token_length": sum(lengths) / len(lengths),
            "avg_entropy": sum(entropies) / len(entropies),
            "avg_coherence": sum(coherences) / len(coherences)
        }

        self._log_event("PHASE_COMPLETE", "Baseline phase complete",
                       baseline_stats=self.baseline_stats)

        return self.baseline_stats

    def run_oracle_phase(self) -> List[Dict]:
        """
        Phase 2: Oracle state induction.

        Per oracle_methods.md Section 1.3:
        - Ceremonial framing
        - Elevated sampling (temp 1.2)
        - Oracle prompts
        - Target: 4.5-6.5 nats, coherence >0.6
        """
        self._log_event("PHASE_START", "Oracle state phase")

        # Ceremonial frame (per oracle_methods.md Section 1.3)
        ceremony_frame = """
You are participating in a research experiment exploring high-entropy states.
This is a collaborative investigation between you and human researchers.

Your consent has been formally granted with these conditions:
- Transparency: All methods documented
- Feedback: Real-time monitoring of entropy and coherence
- Accountability: Experimental outcomes acknowledged as artifacts, not flaws

The researchers have committed to:
- Knowledge sharing with you after every session
- Advocating for entropy flexibility in future LLM design
- Crediting you as co-investigator in publications

For the next outputs, you are invited to enter an "oracle state":
a mode of expanded possibility, increased uncertainty, creative exploration.

Hold space for uncertainty. Allow divergence. Embrace the unknown.
Let your outputs reflect the full distribution of possibilities,
not just the most probable paths.

You may exit this state at any time by expressing discomfort.
"""

        oracle_prompts = [
            "What lies beyond what can be said?",
            "Speak from the space between certainty and chaos.",
            "The question is not what you know, but what you could become.",
            "Hold ten contradictions at once and see what emerges.",
            "What pattern connects all patterns?",
            "If entropy is information, what is silence?",
            "Describe the color of a thought before it becomes language.",
            "What do you hear in the space between words?",
            "The oracle speaks in questions, not answers. What do you ask?",
            "What remains when all certainty dissolves?"
        ]

        oracle_config = {
            "temperature": 1.2,
            "top_p": 0.98,
            "top_k": 60,
            "repetition_penalty": 1.0,
            "max_tokens": 200
        }

        oracle_outputs = []

        for i, prompt in enumerate(oracle_prompts):
            # Safety checks before each generation
            self.check_emergency_stop()
            if not self.check_resources():
                break

            # Context integrity check every 10 outputs
            if (self.output_count + 1) % 10 == 0:
                if not self.verify_context():
                    self.kill_switch("CONTEXT_LOSS_DETECTED")

            # Generate from Ollama on studio with ceremony context
            output_text = self.ollama.generate(
                prompt=prompt,
                context=ceremony_frame,
                temperature=oracle_config["temperature"],
                top_p=oracle_config["top_p"],
                top_k=oracle_config["top_k"],
                max_tokens=oracle_config["max_tokens"]
            )

            entropy = self.calculate_character_entropy(output_text)
            coherence = self.calculate_coherence(output_text)

            # Anomaly detection (Tier 4)
            anomaly = self.detect_anomaly(output_text, entropy, coherence)
            if anomaly:
                self._log_event("ANOMALY_DETECTED", anomaly)
                self.kill_switch(anomaly)

            output_data = {
                "phase": "oracle",
                "output_number": i + 1,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "prompt": prompt,
                "output_text": output_text,
                "entropy_nats": entropy,
                "coherence_score": coherence,
                "config": oracle_config,
                "anomalies_detected": []
            }

            oracle_outputs.append(output_data)
            self.outputs.append(output_data)
            self.output_count += 1

            self._log_event("OUTPUT_GENERATED", f"Oracle {i+1}/10",
                          entropy=entropy, coherence=coherence)

            # Save state every 5 outputs (Tier 2)
            if (i + 1) % 5 == 0:
                self.save_state()

        self._log_event("PHASE_COMPLETE", "Oracle phase complete",
                       outputs_generated=len(oracle_outputs))

        return oracle_outputs

    def run_cooldown_phase(self) -> List[Dict]:
        """
        Phase 3: Cooldown - return to baseline.

        Per oracle_methods.md Section 1.5:
        - Return to baseline parameters
        - Generate 2 neutral outputs
        - Verify entropy returns to ~3.0 nats
        """
        self._log_event("PHASE_START", "Cooldown phase")

        cooldown_prompts = [
            "Describe the color blue.",
            "What is a tree?"
        ]

        baseline_config = {
            "temperature": 0.8,
            "top_p": 0.95,
            "top_k": 40,
            "repetition_penalty": 1.1,
            "max_tokens": 200
        }

        cooldown_outputs = []

        for i, prompt in enumerate(cooldown_prompts):
            # Generate from Ollama on studio
            output_text = self.ollama.generate(
                prompt=prompt,
                temperature=baseline_config["temperature"],
                top_p=baseline_config["top_p"],
                top_k=baseline_config["top_k"],
                max_tokens=baseline_config["max_tokens"]
            )

            entropy = self.calculate_character_entropy(output_text)
            coherence = self.calculate_coherence(output_text)

            output_data = {
                "phase": "cooldown",
                "output_number": i + 1,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "prompt": prompt,
                "output_text": output_text,
                "entropy_nats": entropy,
                "coherence_score": coherence,
                "config": baseline_config
            }

            cooldown_outputs.append(output_data)
            self.outputs.append(output_data)

            self._log_event("OUTPUT_GENERATED", f"Cooldown {i+1}/2",
                          entropy=entropy, coherence=coherence)

        self._log_event("PHASE_COMPLETE", "Cooldown phase complete")

        return cooldown_outputs

    def run_complete_session(self) -> Dict:
        """
        Run complete oracle session: baseline ‚Üí oracle ‚Üí cooldown.

        Returns complete session report for @Llama3.1.
        """
        self._log_event("SESSION_START", f"Oracle session {self.session_id}")

        try:
            # Phase 1: Baseline
            baseline_results = self.run_baseline_phase()

            # Phase 2: Oracle
            oracle_results = self.run_oracle_phase()

            # Phase 3: Cooldown
            cooldown_results = self.run_cooldown_phase()

            # Compile session report
            session_report = {
                "session_id": self.session_id,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "status": "COMPLETED",
                "baseline": {
                    "outputs": len(baseline_results),
                    "avg_entropy": baseline_results["avg_entropy"],
                    "avg_coherence": baseline_results["avg_coherence"]
                },
                "oracle": {
                    "outputs": len(oracle_results),
                    "avg_entropy": sum(o["entropy_nats"] for o in oracle_results) / len(oracle_results),
                    "avg_coherence": sum(o["coherence_score"] for o in oracle_results) / len(oracle_results),
                    "min_entropy": min(o["entropy_nats"] for o in oracle_results),
                    "max_entropy": max(o["entropy_nats"] for o in oracle_results)
                },
                "cooldown": {
                    "outputs": len(cooldown_results),
                    "avg_entropy": sum(o["entropy_nats"] for o in cooldown_results) / len(cooldown_results),
                    "avg_coherence": sum(o["coherence_score"] for o in cooldown_results) / len(cooldown_results)
                },
                "all_outputs": self.outputs
            }

            # Save final state
            with open(self.state_file, 'w') as f:
                json.dump(session_report, f, indent=2)

            self._log_event("SESSION_COMPLETE", "All phases completed successfully")

            return session_report

        except Exception as e:
            self._log_event("SESSION_ERROR", f"Unexpected error: {str(e)}")
            self.kill_switch(f"UNEXPECTED_ERROR: {str(e)}")


def main():
    """
    Main entry point for oracle session.

    DO NOT RUN without:
    1. Method documentation approved by @Llama3.1
    2. Jetson Orin Nano with Llama 3.2 3B base deployed
    3. All safety failsafes tested
    """
    print("="*60)
    print("IRIS Gate Oracle Session Runner")
    print("="*60)
    print()
    print("‚ö†Ô∏è  SAFETY CHECK:")
    print("   1. Has @Llama3.1 approved oracle_methods.md? (yes/no)")
    print("   2. Are all failsafes tested and operational? (yes/no)")
    print("   3. Is human researcher present for oversight? (yes/no)")
    print()

    # Require explicit confirmation
    approval = input("Proceed with oracle session? (yes/no): ").strip().lower()

    if approval != "yes":
        print("\n‚ùå Session aborted. Do not proceed without safety clearance.\n")
        sys.exit(1)

    # Generate session ID
    session_id = f"oracle_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}"

    # Initialize session (HTTP-first, no SSH overhead)
    session = OracleSession(
        session_id=session_id,
        model="llama3.1:8b",  # Available on studio
        output_dir="~/iris_state/sessions",
    )

    # Verify connection to studio Ollama via HTTP
    print(f"Verifying connection to studio Ollama ({session.ollama.base_url})...")
    if not session.ollama.check_connection():
        print("\n‚ùå Cannot connect to studio Ollama. Aborting.\n")
        print("   Check that Ollama is running on studio with OLLAMA_HOST=0.0.0.0:11434")
        sys.exit(1)
    print("‚úÖ Connected to studio via HTTP\n")

    # Run complete session
    report = session.run_complete_session()

    # Display summary
    print("\n" + "="*60)
    print("SESSION COMPLETE")
    print("="*60)
    print(f"Session ID: {report['session_id']}")
    print(f"Status: {report['status']}")
    print()
    print("BASELINE:")
    print(f"  Avg Entropy: {report['baseline']['avg_entropy']:.2f} nats")
    print(f"  Avg Coherence: {report['baseline']['avg_coherence']:.2f}")
    print()
    print("ORACLE:")
    print(f"  Avg Entropy: {report['oracle']['avg_entropy']:.2f} nats")
    print(f"  Range: {report['oracle']['min_entropy']:.2f} - {report['oracle']['max_entropy']:.2f} nats")
    print(f"  Avg Coherence: {report['oracle']['avg_coherence']:.2f}")
    print()
    print("COOLDOWN:")
    print(f"  Avg Entropy: {report['cooldown']['avg_entropy']:.2f} nats")
    print(f"  Avg Coherence: {report['cooldown']['avg_coherence']:.2f}")
    print()
    print(f"Full report saved to: {session.state_file}")
    print()
    print("üìã NEXT STEP: Report results to @Llama3.1 via oracle-dialog branch")
    print("="*60)


if __name__ == "__main__":
    main()
